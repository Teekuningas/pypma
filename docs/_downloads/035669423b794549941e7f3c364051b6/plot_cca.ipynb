{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Different CCA methods\n\nExempliefies different CCA methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary libraries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom numpy.linalg import svd\nfrom statsmodels.multivariate.cancorr import CanCorr\n\nfrom sparsecca import cca_ipls\nfrom sparsecca import cca_pmd\nfrom sparsecca import multicca_pmd\nfrom sparsecca import pmd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulate correlated datasets so that 1st and 2nd variable of X dataset are correlated with 2nd, 3rd and 4th variables of the Z dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For consistency\nrand_state = np.random.RandomState(15)\n\n# Simulate correlated datasets\nu_ = np.concatenate([np.ones(125), np.zeros(375)])\nv1 = np.concatenate([np.ones(2), np.zeros(4)])\nv2 = np.concatenate([np.zeros(1), np.ones(3), np.zeros(1)])\nX = u_[:, np.newaxis] @ v1[np.newaxis, :] + rand_state.randn(500*6).reshape(500, 6)\nZ = u_[:, np.newaxis] @ v2[np.newaxis, :] + rand_state.randn(500*5).reshape(500, 5)\n\n# standardize\nX = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\nZ = (Z - np.mean(Z, axis=0)) / np.std(Z, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define function for printing weights\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def print_weights(name, weights):\n    first = weights[:, 0]\n    print(name + ': ' + ', '.join(['{:.3f}'.format(item) for item in first / np.max(first)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's try CanCorr function from statsmodels package.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stats_cca = CanCorr(Z, X)\n\nprint(stats_cca.corr_test().summary())\nprint_weights('X', stats_cca.x_cancoef)\nprint_weights('Z', stats_cca.y_cancoef)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, use CCA algorithm from Witten et al.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "U, V, D = cca_pmd(X, Z, penaltyx=1.0, penaltyz=1.0, K=2, standardize=False)\n\nx_weights = U[:, 0]\nz_weights = V[:, 0]\ncorrcoef = np.corrcoef(np.dot(x_weights, X.T), np.dot(z_weights, Z.T))[0, 1]\nprint(\"Corrcoef for comp 1: \" + str(corrcoef))\n\nprint_weights('X', U)\nprint_weights('Z', V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the CCA algorithm in Witten et al is faster version of \ncomputing SVD of X.T @ Z, try that.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "U, D, V = svd(X.T @ Z)\n\nx_weights = U[:, 0]\nz_weights = V[0, :]\ncorrcoef = np.corrcoef(np.dot(x_weights, X.T), np.dot(z_weights, Z.T))[0, 1]\nprint(\"Corrcoef for comp 1: \" + str(corrcoef))\n\nprint_weights('X', U)\nprint_weights('V', V.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The novelty in Witten et al is developing matrix decomposition similar\nto SVD, but which allows to add convex penalties (here lasso).\nUsing that to X.T @ Z without penalty results to same as above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "U, V, D = pmd(X.T @ Z, K=2, penaltyu=1.0, penaltyv=1.0, standardize=False)\n\nx_weights = U[:, 0]\nz_weights = V[:, 0]\ncorrcoef = np.corrcoef(np.dot(x_weights, X.T), np.dot(z_weights, Z.T))[0, 1]\nprint(\"Corrcoef for comp 1: \" + str(corrcoef))\n\nprint_weights('X', U)\nprint_weights('Z', V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, when you add penalties, you get a sparse version of CCA.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "U, V, D = pmd(X.T @ Z, K=2, penaltyu=0.9, penaltyv=0.9, standardize=False)\n\nx_weights = U[:, 0]\nz_weights = V[:, 0]\ncorrcoef = np.corrcoef(np.dot(x_weights, X.T), np.dot(z_weights, Z.T))[0, 1]\nprint(\"Corrcoef for comp 1: \" + str(corrcoef))\n\nprint_weights('X', U)\nprint_weights('Z', V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PMD is really fantastically simple and powerful idea, and as seen, \ncan be used to implement sparse CCA. However, for SVD(X.T @ Z) to be \nequivalent to CCA, cov(X) and cov(Z) should be diagonal,\nwhich can sometimes give problems. Another CCA algorithm allowing convex penalties\nthat does not require cov(X) and cov(Z) to be diagonal, was presented in \nMai et al (2019). It is based on iterative least squares formulation, and as it is\nsolved with GLM, it allows elastic net -like weighting of L1 and L2 -norms for \nboth datasets separately.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_weights, Z_weights = cca_ipls(X, Z, alpha_lambda=0.0, beta_lambda=0.0, standardize=False,\n                                n_pairs=2, glm_impl='glmnet_python')\n\nx_weights = X_weights[:, 0]\nz_weights = Z_weights[:, 0]\ncorrcoef = np.corrcoef(np.dot(x_weights, X.T), np.dot(z_weights, Z.T))[0, 1]\nprint(\"Corrcoef for comp 1: \" + str(corrcoef))\n\nprint_weights(\"X\", X_weights)\nprint_weights(\"Z\", Z_weights)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}